name: dbt CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run daily at 6 AM UTC for data freshness monitoring
    - cron: '0 6 * * *'

env:
  DBT_PROFILES_DIR: ./
  DBT_TARGET: ci
  POSTGRES_HOST: localhost
  POSTGRES_PORT: 5432
  POSTGRES_USER: dbt_user
  POSTGRES_PASSWORD: dbt_password
  POSTGRES_DB: ecommerce_dw_ci

jobs:
  # Job 1: Code Quality and Compilation
  lint-and-compile:
    name: Lint and Compile
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Lint SQL files
        run: |
          # Install sqlfluff for SQL linting
          pip install sqlfluff
          sqlfluff lint dbt_project/models/ --dialect postgres || true
          
      - name: Check Python code quality
        run: |
          # Install and run code quality tools
          pip install black flake8 isort
          black --check scripts/ || true
          flake8 scripts/ || true
          isort --check scripts/ || true
          
      - name: dbt deps
        run: |
          cd dbt_project
          dbt deps
          
      - name: dbt compile
        run: |
          cd dbt_project
          dbt compile --target ci
          
      - name: Upload compiled artifacts
        uses: actions/upload-artifact@v3
        with:
          name: compiled-dbt-models
          path: dbt_project/target/

  # Job 2: Data Testing and Quality Checks
  test-data-quality:
    name: Data Quality Tests
    runs-on: ubuntu-latest
    needs: lint-and-compile
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: dbt_user
          POSTGRES_PASSWORD: dbt_password
          POSTGRES_DB: ecommerce_dw_ci
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Generate test data
        run: |
          # Generate smaller dataset for CI testing
          python -c "
          import sys
          sys.path.append('scripts')
          from generate_sample_data import EcommerceDataGenerator
          
          generator = EcommerceDataGenerator(num_customers=1000)
          generator.generate_complete_dataset(
              num_customers=1000,
              num_products=500,
              num_orders=2000,
              num_sessions=5000
          )
          generator.save_all_data('data/raw')
          "
          
      - name: Load test data to database
        run: |
          python -c "
          import pandas as pd
          from sqlalchemy import create_engine
          import os
          
          engine = create_engine('postgresql://dbt_user:dbt_password@localhost:5432/ecommerce_dw_ci')
          
          data_files = {
              'customers': 'data/raw/customers.csv',
              'products': 'data/raw/products.csv',
              'orders': 'data/raw/orders.csv',
              'order_items': 'data/raw/order_items.csv',
              'web_sessions': 'data/raw/web_sessions.csv',
              'marketing_spend': 'data/raw/marketing_spend.csv'
          }
          
          for table_name, file_path in data_files.items():
              if os.path.exists(file_path):
                  df = pd.read_csv(file_path)
                  df.to_sql(table_name, engine, if_exists='replace', index=False)
                  print(f'Loaded {len(df)} records to {table_name}')
          "
          
      - name: dbt deps
        run: |
          cd dbt_project
          dbt deps
          
      - name: dbt seed
        run: |
          cd dbt_project
          dbt seed --target ci
          
      - name: dbt run - staging models
        run: |
          cd dbt_project
          dbt run --select staging --target ci
          
      - name: dbt test - staging models
        run: |
          cd dbt_project
          dbt test --select staging --target ci
          
      - name: dbt run - intermediate models
        run: |
          cd dbt_project
          dbt run --select intermediate --target ci
          
      - name: dbt run - marts models
        run: |
          cd dbt_project
          dbt run --select marts --target ci
          
      - name: dbt test - all models
        run: |
          cd dbt_project
          dbt test --target ci
          
      - name: Generate dbt docs
        run: |
          cd dbt_project
          dbt docs generate --target ci
          
      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: dbt-test-results
          path: |
            dbt_project/target/run_results.json
            dbt_project/target/manifest.json
            dbt_project/target/catalog.json

  # Job 3: Performance Testing
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: test-data-quality
    if: github.event_name == 'pull_request'
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: dbt_user
          POSTGRES_PASSWORD: dbt_password
          POSTGRES_DB: ecommerce_dw_ci
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Run performance benchmarks
        run: |
          cd dbt_project
          # Run models with timing
          dbt run --target ci --log-level info
          
          # Extract timing information
          python -c "
          import json
          with open('target/run_results.json', 'r') as f:
              results = json.load(f)
          
          print('Performance Summary:')
          for result in results['results']:
              if result['status'] == 'success':
                  execution_time = result['execution_time']
                  print(f'{result[\"unique_id\"]}: {execution_time:.2f}s')
          "

  # Job 4: Security Scanning
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          
      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

  # Job 5: Deploy to Staging (only on main branch)
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [test-data-quality, performance-tests]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: staging
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Deploy to staging
        env:
          STAGING_HOST: ${{ secrets.STAGING_HOST }}
          STAGING_USER: ${{ secrets.STAGING_USER }}
          STAGING_PASSWORD: ${{ secrets.STAGING_PASSWORD }}
        run: |
          cd dbt_project
          dbt deps
          dbt run --target staging
          dbt test --target staging
          
      - name: Run post-deployment tests
        run: |
          cd dbt_project
          # Run additional validation queries
          dbt run-operation check_data_freshness --target staging

  # Job 6: Deploy to Production (manual trigger)
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: deploy-staging
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Deploy to production
        env:
          PROD_HOST: ${{ secrets.PROD_HOST }}
          PROD_USER: ${{ secrets.PROD_USER }}
          PROD_PASSWORD: ${{ secrets.PROD_PASSWORD }}
        run: |
          cd dbt_project
          dbt deps
          
          # Run with fail-fast to stop on first error
          dbt run --target prod --fail-fast
          dbt test --target prod --fail-fast
          
      - name: Generate production documentation
        run: |
          cd dbt_project
          dbt docs generate --target prod
          
      - name: Upload production docs
        uses: actions/upload-artifact@v3
        with:
          name: production-docs
          path: dbt_project/target/

  # Job 7: Data Freshness Monitoring (scheduled runs)
  data-freshness:
    name: Data Freshness Check
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Check data freshness
        env:
          PROD_HOST: ${{ secrets.PROD_HOST }}
          PROD_USER: ${{ secrets.PROD_USER }}
          PROD_PASSWORD: ${{ secrets.PROD_PASSWORD }}
        run: |
          cd dbt_project
          dbt deps
          dbt source freshness --target prod
          
      - name: Notify on freshness issues
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          text: 'Data freshness check failed! Please investigate source data delays.'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # Job 8: Notification and Reporting
  notify-completion:
    name: Notify Completion
    runs-on: ubuntu-latest
    needs: [test-data-quality, performance-tests, security-scan]
    if: always()
    
    steps:
      - name: Notify success
        if: ${{ needs.test-data-quality.result == 'success' && needs.performance-tests.result == 'success' }}
        uses: 8398a7/action-slack@v3
        with:
          status: success
          text: '✅ dbt CI/CD pipeline completed successfully!'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          
      - name: Notify failure
        if: ${{ needs.test-data-quality.result == 'failure' || needs.performance-tests.result == 'failure' }}
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          text: '❌ dbt CI/CD pipeline failed! Check GitHub Actions for details.'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}